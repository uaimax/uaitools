# Configura√ß√£o do Celery Worker no CapRover

## üìã Vis√£o Geral

O Celery Worker √© necess√°rio para processar tarefas ass√≠ncronas, como:
- Transcri√ß√£o de √°udio (bau_mental)
- Classifica√ß√£o de anota√ß√µes
- Outras tarefas ass√≠ncronas

## üîß Configura√ß√£o no CapRover

### ‚ö° Configura√ß√£o Padr√£o: Mesmo Container (Recomendado para MVP)

**Por padr√£o, o Celery Worker roda no mesmo container do backend** usando Supervisor para gerenciar ambos os processos (Gunicorn + Celery).

**Vantagens:**
- ‚úÖ Simplicidade: Um √∫nico app no CapRover
- ‚úÖ Economia: Menos recursos consumidos
- ‚úÖ Deploy √∫nico: Menos complexidade
- ‚úÖ Adequado para baixo/m√©dio tr√°fego

**Como funciona:**
- O `captain-definition` j√° est√° configurado com Supervisor
- Supervisor gerencia Gunicorn (backend HTTP) e Celery Worker simultaneamente
- Auto-restart autom√°tico em caso de falha
- Logs separados por processo

**Nenhuma configura√ß√£o adicional necess√°ria!** Apenas certifique-se de que as vari√°veis de ambiente do Redis est√£o configuradas:
```bash
CELERY_BROKER_URL=redis://:SENHA@srv-captain--redis:6379/0
CELERY_RESULT_BACKEND=redis://:SENHA@srv-captain--redis:6379/0
```

### Op√ß√£o 2: Servi√ßo Separado (Para Escala Futura)

**Quando usar:** Quando a carga for alta (>500 uploads/dia) ou precisar escalar workers independentemente.

Crie um **novo app** no CapRover chamado `ut-be-celery` (ou outro nome de sua escolha):

1. **Criar novo app no CapRover:**
   - Nome: `ut-be-celery` (ou `ut-be-worker`)
   - Captain Definition File: `backend/captain-definition-celery.json`

2. **Configurar vari√°veis de ambiente:**
   - Copie **todas** as vari√°veis de ambiente do app backend
   - Especialmente importantes:
     ```bash
     CELERY_BROKER_URL=redis://:y8JtINWf^%23@srv-captain--redis:6379/0
     CELERY_RESULT_BACKEND=redis://:y8JtINWf^%23@srv-captain--redis:6379/0
     DATABASE_URL=postgresql://...
     OPENAI_API_KEY=sk-...
     ENVIRONMENT=production
     ```

3. **Configurar modo separado no backend:**
   - No app backend, adicione vari√°vel de ambiente:
     ```bash
     CELERY_MODE=separate
     ```
   - Isso far√° o backend rodar apenas Gunicorn (sem Celery)

4. **Deploy:**
   - Fa√ßa deploy do novo app Celery
   - Fa√ßa deploy do backend (com `CELERY_MODE=separate`)
   - O Celery worker iniciar√° automaticamente no servi√ßo separado

### Op√ß√£o 2: Mesmo Container (N√£o Recomendado)

Voc√™ pode modificar o `captain-definition` do backend para iniciar Gunicorn e Celery no mesmo container, mas isso n√£o √© recomendado porque:
- Se um processo falhar, ambos param
- Dificulta escalonamento independente
- Dificulta monitoramento

## üîç Verificar se Celery est√° Funcionando

### 1. Verificar Logs do Worker

```bash
# Ver logs do app Celery no CapRover
caprover logs -a ut-be-celery
```

Voc√™ deve ver:
```
[tasks]
  . apps.bau_mental.tasks.transcribe_audio
  . apps.bau_mental.tasks.classify_note
```

### 2. Verificar Tasks Pendentes

```bash
# Conectar ao container do backend
caprover exec -a ut-be "python manage.py shell"

# No shell Python:
from config.celery import app
inspect = app.control.inspect()
print(inspect.active())  # Tasks ativas
print(inspect.scheduled())  # Tasks agendadas
print(inspect.reserved())  # Tasks reservadas
```

### 3. Testar Task Manualmente

```bash
# No shell do Django
from apps.bau_mental.tasks import transcribe_audio
from apps.bau_mental.models import Note

# Pegar uma nota pendente
note = Note.objects.filter(processing_status='pending').first()
if note:
    result = transcribe_audio.delay(str(note.id))
    print(f"Task ID: {result.id}")
    print(f"Status: {result.status}")
```

## üö® Troubleshooting

### Worker n√£o est√° processando tasks

1. **Verificar conex√£o com Redis:**
   ```bash
   caprover exec -a ut-be-celery "python -c 'import redis; r=redis.from_url(\"redis://:y8JtINWf^%23@srv-captain--redis:6379/0\"); print(r.ping())'"
   ```
   Deve retornar: `True`

2. **Verificar se tasks est√£o sendo enfileiradas:**
   ```bash
   caprover exec -s srv-captain--redis "redis-cli -a 'y8JtINWf^#'"
   # No redis-cli:
   SELECT 0
   KEYS celery*
   LLEN celery  # Ver quantas tasks est√£o na fila
   ```

3. **Verificar logs do worker:**
   ```bash
   caprover logs -a ut-be-celery --tail 100
   ```

### Tasks falhando

1. **Verificar OPENAI_API_KEY:**
   ```bash
   caprover exec -a ut-be-celery "python -c 'import os; print(\"OK\" if os.getenv(\"OPENAI_API_KEY\") else \"FALTANDO\")'"
   ```

2. **Verificar acesso ao banco de dados:**
   ```bash
   caprover exec -a ut-be-celery "python manage.py check --database default"
   ```

3. **Verificar acesso ao storage (R2/S3):**
   - Verifique se as credenciais est√£o configuradas
   - Verifique se o worker tem acesso √† rede para acessar R2/S3

## üìù Checklist de Configura√ß√£o

- [ ] App `ut-be-celery` criado no CapRover
- [ ] Captain Definition File configurado (`backend/captain-definition-celery.json`)
- [ ] Vari√°veis de ambiente copiadas do backend
- [ ] `CELERY_BROKER_URL` configurada corretamente
- [ ] `CELERY_RESULT_BACKEND` configurada corretamente
- [ ] `OPENAI_API_KEY` configurada (para transcri√ß√µes)
- [ ] `DATABASE_URL` configurada
- [ ] Deploy realizado com sucesso
- [ ] Logs mostram worker iniciado
- [ ] Tasks sendo processadas (verificar logs)

## üîÑ Celery Beat (Tarefas Peri√≥dicas)

Se precisar de tarefas peri√≥dicas (ex: limpeza de √°udios expirados), voc√™ pode adicionar um terceiro servi√ßo para Celery Beat:

1. Criar app `ut-be-celery-beat`
2. Usar mesmo `captain-definition-celery.json`
3. Modificar CMD para: `celery -A config beat -l info`

**Por enquanto, n√£o √© necess√°rio** - as tasks s√£o disparadas apenas quando h√° upload de √°udio.

