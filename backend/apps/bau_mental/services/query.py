"""Servi√ßo para consultas inteligentes com IA."""

import json
import os
from typing import Any, Dict, List

try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    OpenAI = None


class QueryService:
    """Servi√ßo para consultas inteligentes com IA."""

    def __init__(self) -> None:
        """Inicializa o servi√ßo de consulta."""
        # Aceita tanto OPENAI_API_KEY quanto OPENAI_KEY (compatibilidade)
        self.api_key = os.getenv("OPENAI_API_KEY") or os.getenv("OPENAI_KEY") or os.getenv("ANTHROPIC_API_KEY")
        if OPENAI_AVAILABLE and self.api_key:
            self.client = OpenAI(api_key=self.api_key)
        else:
            self.client = None

    def is_available(self) -> bool:
        """Verifica se o servi√ßo est√° dispon√≠vel."""
        return OPENAI_AVAILABLE and self.client is not None

    def _estimar_tokens(self, texto: str) -> int:
        """Estima quantidade de tokens (1 token ‚âà 4 caracteres em portugu√™s)."""
        return len(texto) // 4

    def query(
        self, question: str, notes: List[Dict[str, Any]], workspace_id: str, box_id: str | None = None
    ) -> Dict[str, Any]:
        """Responde pergunta com base nas anota√ß√µes.

        Implementa l√≥gica de contexto completo vs reduzido conforme PRD:
        - Se total_tokens < 80000: manda todas as notas (ordem cronol√≥gica)
        - Se total_tokens >= 80000: contexto reduzido (resumo + recentes + full-text match)

        Args:
            question: Pergunta do usu√°rio
            notes: Lista de anota√ß√µes relevantes
                [{
                    "id": "uuid",
                    "transcript": "texto",
                    "created_at": "2025-01-27",
                    "box_name": "Casa",
                }, ...]
            workspace_id: ID do workspace
            box_id: ID da caixinha (opcional, para contexto reduzido)

        Returns:
            {
                "answer": "Resposta da IA",
                "sources": [
                    {
                        "note_id": "uuid",
                        "excerpt": "trecho relevante",
                        "date": "2025-01-27",
                        "box_name": "Casa",
                    }
                ],
            }

        Raises:
            ValueError: Se servi√ßo n√£o est√° dispon√≠vel
            Exception: Se erro ao consultar
        """
        if not self.is_available():
            raise ValueError(
                "OpenAI n√£o est√° dispon√≠vel. Verifique OPENAI_API_KEY no .env"
            )

        if not notes:
            return {
                "answer": "N√£o encontrei anota√ß√µes relevantes para sua pergunta.",
                "sources": [],
            }

        try:
            # Estimar tokens totais
            total_tokens = sum(self._estimar_tokens(note.get('transcript', '')) for note in notes)
            LIMITE_SEGURO = 80000  # tokens

            # Ordenar notas por created_at (mais antiga primeiro) - ordem cronol√≥gica
            notes_sorted = sorted(notes, key=lambda n: n.get('created_at', ''))

            # Decidir contexto: completo ou reduzido
            if total_tokens < LIMITE_SEGURO:
                # CONTEXTO COMPLETO: manda todas as notas
                notes_to_use = notes_sorted
            else:
                # CONTEXTO REDUZIDO: resumo + recentes + top 10 por full-text match
                # Por enquanto, vamos usar apenas recentes + top 10
                # (resumo ser√° implementado quando tiver cache de resumo)
                recentes = notes_sorted[-30:]  # √öltimas 30 notas
                # Top 10 por full-text match j√° vem ordenado do viewset
                top_matches = notes_sorted[:10]
                
                # Combinar e remover duplicatas mantendo ordem
                seen_ids = set()
                notes_to_use = []
                for note in top_matches + recentes:
                    note_id = note.get('id')
                    if note_id and note_id not in seen_ids:
                        seen_ids.add(note_id)
                        notes_to_use.append(note)

            # Construir contexto com anota√ß√µes (ordem cronol√≥gica)
            notes_text = "\n\n".join(
                [
                    f"üìÖ {note['created_at']} - {note.get('box_name', 'Inbox')}\n"
                    f"{note['transcript']}"
                    for note in notes_to_use
                ]
            )

            system_prompt = """Voc√™ √© um assistente que responde perguntas baseado APENAS nas anota√ß√µes transcritas fornecidas.

REGRAS CR√çTICAS:
1. Voc√™ S√ì pode responder com informa√ß√µes que estejam EXPLICITAMENTE nas anota√ß√µes fornecidas
2. Se a informa√ß√£o n√£o estiver nas anota√ß√µes, voc√™ DEVE dizer claramente "N√£o encontrei essa informa√ß√£o nas minhas anota√ß√µes" ou "N√£o tenho essa informa√ß√£o dispon√≠vel"
3. NUNCA invente, suponha ou presuma informa√ß√µes que n√£o estejam nas anota√ß√µes
4. Se as anota√ß√µes n√£o cont√™m informa√ß√£o suficiente para responder, seja honesto sobre isso

Sua tarefa:
1. Analisar as anota√ß√µes fornecidas
2. Responder APENAS com base no que est√° explicitamente nas anota√ß√µes
3. Se n√£o houver informa√ß√£o relevante, diga claramente que n√£o encontrou
4. Incluir refer√™ncias √†s anota√ß√µes usadas (data e caixinha) quando houver informa√ß√£o

Formato da resposta:
- Resposta direta e objetiva
- Se n√£o houver informa√ß√£o: "N√£o encontrei essa informa√ß√£o nas minhas anota√ß√µes"
- Se houver informa√ß√£o: inclua datas e contextos quando relevante
- Use emojis para clareza visual (üìÖ para datas, üì¶ para caixinhas)
- Seja conciso mas completo"""

            user_prompt = f"""Anota√ß√µes dispon√≠veis:

{notes_text}

---

Pergunta do usu√°rio:
{question}

IMPORTANTE: Responda APENAS com base nas anota√ß√µes fornecidas acima. Se a informa√ß√£o n√£o estiver nas anota√ß√µes, diga claramente "N√£o encontrei essa informa√ß√£o nas minhas anota√ß√µes". N√ÉO invente ou presuma informa√ß√µes. Seja objetivo e inclua refer√™ncias (data e caixinha) quando houver informa√ß√£o relevante."""

            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
                temperature=0.5,
                max_tokens=1000,
            )

            answer = response.choices[0].message.content or "N√£o foi poss√≠vel gerar resposta."

            # Extrair fontes (anota√ß√µes usadas)
            # Por enquanto, retornamos todas as anota√ß√µes fornecidas como fontes
            # Futuramente, podemos melhorar para identificar quais foram realmente usadas
            sources = [
                {
                    "note_id": note["id"],
                    "excerpt": note["transcript"][:200] + "..."
                    if len(note["transcript"]) > 200
                    else note["transcript"],
                    "date": note["created_at"],
                    "box_name": note.get("box_name", "Inbox"),
                }
                for note in notes
            ]

            return {
                "answer": answer,
                "sources": sources,
            }

        except Exception as e:
            raise Exception(f"Erro ao consultar IA: {str(e)}") from e


